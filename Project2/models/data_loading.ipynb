{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "data_path = path.join(\"..\", \"data\")\n",
    "\n",
    "train_files = {\n",
    "    \"raw\": path.join(data_path, \"train-raw.tsv\"),\n",
    "    \"top10\": path.join(data_path, \"train-top10.csv\"),\n",
    "    \"top50\": path.join(data_path, \"train-top50.csv\"),\n",
    "    \"top100\": path.join(data_path, \"train-top100.csv\"),\n",
    "}\n",
    "\n",
    "test_files = {\n",
    "    \"raw\": path.join(data_path, \"test-raw.tsv\"),\n",
    "    \"top10\": path.join(data_path, \"test-top10.csv\"),\n",
    "    \"top50\": path.join(data_path, \"test-top50.csv\"),\n",
    "    \"top100\": path.join(data_path, \"test-top100.csv\"),\n",
    "}\n",
    "\n",
    "dev_files = {\n",
    "    \"raw\": path.join(data_path, \"dev-raw.tsv\"),\n",
    "    \"top10\": path.join(data_path, \"dev-top10.csv\"),\n",
    "    \"top50\": path.join(data_path, \"dev-top50.csv\"),\n",
    "    \"top100\": path.join(data_path, \"dev-top100.csv\"),\n",
    "}\n",
    "\n",
    "all_files = {\n",
    "    \"train\": train_files,\n",
    "    \"dev\": dev_files,\n",
    "    \"test\": test_files\n",
    "}\n",
    "\n",
    "\n",
    "def load_data_file(type=\"train\", content=\"top10\"):\n",
    "    try:\n",
    "        file = all_files[type][content]\n",
    "        sep = \",\"\n",
    "        if file.endswith(\".tsv\"):\n",
    "            sep = \"\\t\"\n",
    "        return pd.read_csv(file, sep=sep)\n",
    "    except:\n",
    "        print(f\"Unable to load {type} {content}\")\n",
    "        \n",
    "# train_raw = pd.read_csv(train_files[\"raw\"], sep=\"\\t\")\n",
    "# train_10 = pd.read_csv(train_files[\"top10\"])\n",
    "# train_50 = pd.read_csv(train_files[\"top50\"])\n",
    "# train_100 = pd.read_csv(train_files[\"top100\"])\n",
    "# \n",
    "# test_raw = pd.read_csv(test_files[\"raw\"], sep=\"\\t\")\n",
    "# test_10 = pd.read_csv(test_files[\"top10\"])\n",
    "# test_50 = pd.read_csv(test_files[\"top50\"])\n",
    "# test_100 = pd.read_csv(test_files[\"top100\"])\n",
    "# \n",
    "# dev_raw = pd.read_csv(dev_files[\"raw\"], sep=\"\\t\")\n",
    "# dev_10 = pd.read_csv(dev_files[\"top10\"])\n",
    "# dev_50 = pd.read_csv(dev_files[\"top50\"])\n",
    "# dev_100 = pd.read_csv(dev_files[\"top100\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_unicode(m):\n",
    "    '''process(m) -> Unicode code point\n",
    "\n",
    "    m is a regular expression match object that has groups below:\n",
    "     1: high Unicode surrogate 4-digit hex code d800-dbff\n",
    "     2: low  Unicode surrogate 4-digit hex code dc00-dfff\n",
    "     3: None\n",
    "    OR\n",
    "     1: None\n",
    "     2: None\n",
    "     3: Unicode 4-digit hex code 0000-d700,e000-ffff\n",
    "    '''\n",
    "    if m.group(3) is None:\n",
    "        # Construct code point from UTF-16 surrogates\n",
    "        hi = int(m.group(1),16) & 0x3FF\n",
    "        lo = int(m.group(2),16) & 0x3FF\n",
    "        cp = 0x10000 | hi << 10 | lo\n",
    "    else:\n",
    "        cp = int(m.group(3),16)\n",
    "    return chr(cp)\n",
    "\n",
    "def full_process_unicode(m):\n",
    "    return re.sub(r'\\\\u(d[89ab][0-9a-f]{2})\\\\u(d[cdef][0-9a-f]{2})|\\\\u([0-9a-f]{4})',process_unicode,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
